{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krish-navulla/FL_Breast_Cancer_Classification/blob/main/Thesis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zDyF5NnDo3VZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_-BfP0eB8as"
      },
      "source": [
        "# Creating annotations file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TnKIg8e206a8"
      },
      "outputs": [],
      "source": [
        "annotations_benign = pd.read_csv(\"/content/drive/MyDrive/Thesis/BreaKHis_v1/histology_slides/breast/annotations_benign.txt\", delimiter='\\t')\n",
        "annotations_malignant = pd.read_csv(\"/content/drive/MyDrive/Thesis/BreaKHis_v1/histology_slides/breast/annotations_malignant.txt\", delimiter='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ybohOX4q1HNB"
      },
      "outputs": [],
      "source": [
        "\n",
        "annotations = pd.concat([pd.DataFrame(annotations_malignant, columns=['name', 'value']), pd.DataFrame(annotations_benign, columns=['name', 'value'])])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "il_4F-a4-_30"
      },
      "outputs": [],
      "source": [
        "annotations = annotations.sample(frac=1).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elxgdVchCFpa"
      },
      "source": [
        "# Creating pytorch data loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QKc-1vbJpaKf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image\n",
        "from torch.utils.data import DataLoader, random_split, Dataset\n",
        "from torchvision import transforms\n",
        "\n",
        "class CustomImageDataset():\n",
        "    def __init__(self, annotations_file, img_dir, transform, target_transform=None):\n",
        "        self.img_labels = annotations_file\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0]).replace(\"\\\\\",\"/\")\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "sGoOILbp2A8O"
      },
      "outputs": [],
      "source": [
        "img_dir = \"\\content\\drive\\MyDrive\\Thesis\\BreaKHis_v1\"\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Adjust the size as needed\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "dataset = CustomImageDataset(img_dir = img_dir,annotations_file=annotations, transform = transform)\n",
        "dataset.img_labels = dataset.img_labels[:-1]\n",
        "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8PQsVdV2y3b",
        "outputId": "640bed12-e575-4322-de77-290f1d698859"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7908"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "dataset.__len__()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wc4kBHWCRR1"
      },
      "source": [
        "# Test model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "RjR_mlCaNH-N"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "A-FzXgOE6iu7"
      },
      "outputs": [],
      "source": [
        "dataset_size = len(dataset)\n",
        "client1, client2, client3, client4 = int(0.25 * dataset_size),int(0.25 * dataset_size),int(0.25 * dataset_size), int(0.25 * dataset_size)\n",
        "\n",
        "\n",
        "\n",
        "client1_dataset, client2_dataset, client3_dataset, client4_dataset = random_split(dataset, [client1, client2, client3, client4])\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Client 1"
      ],
      "metadata": {
        "id": "_t9G_NbrW_Vd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.7 * len(client1_dataset))\n",
        "val_size = int(0.15 * len(client1_dataset))\n",
        "test_size = len(client1_dataset) - train_size - val_size\n",
        "num_epochs = 2\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = random_split(client1_dataset, [train_size, val_size, test_size])\n",
        "\n",
        "# Create DataLoader instances for each set\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "2X5se5TdXDAt"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCYFBQSdDe6y",
        "outputId": "c4637dd2-032d-416f-b578-e67384ff55af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Epoch 1/2: 100%|██████████| 22/22 [19:50<00:00, 54.10s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.5510490213023177\n",
            "Validation Accuracy: 71.62%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/2: 100%|██████████| 22/22 [00:25<00:00,  1.16s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.30845355926134066\n",
            "Validation Accuracy: 85.47%\n",
            "Test Accuracy: 87.58%\n"
          ]
        }
      ],
      "source": [
        "client_1_model = models.resnet18(pretrained=True)\n",
        "num_ftrs = client_1_model.fc.in_features\n",
        "client_1_model.fc = nn.Linear(num_ftrs, 2)  # Assuming you have 2 classes\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "client_1_model = client_1_model.to(device)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(client_1_model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 2\n",
        "for epoch in range(num_epochs):\n",
        "    client_1_model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = client_1_model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    print(f\"Train Loss: {epoch_loss}\")\n",
        "\n",
        "    # Evaluation on validation set\n",
        "    client_1_model.eval()\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = client_1_model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            val_total += labels.size(0)\n",
        "            val_correct += (predicted == labels).sum().item()\n",
        "    val_accuracy = 100 * val_correct / val_total\n",
        "    print(f\"Validation Accuracy: {val_accuracy:.2f}%\")\n",
        "\n",
        "# Test the model on the test set\n",
        "client_1_model.eval()\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = client_1_model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        test_total += labels.size(0)\n",
        "        test_correct += (predicted == labels).sum().item()\n",
        "test_accuracy = 100 * test_correct / test_total\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Client 2"
      ],
      "metadata": {
        "id": "6AWlwm7lbKZC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "-b2sSS8gqKan"
      },
      "outputs": [],
      "source": [
        "train_size = int(0.7 * len(client2_dataset))\n",
        "val_size = int(0.15 * len(client2_dataset))\n",
        "test_size = len(client2_dataset) - train_size - val_size\n",
        "num_epochs = 2\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = random_split(client2_dataset, [train_size, val_size, test_size])\n",
        "\n",
        "# Create DataLoader instances for each set\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client_2_model = models.resnet18(pretrained=True)\n",
        "num_ftrs = client_2_model.fc.in_features\n",
        "client_2_model.fc = nn.Linear(num_ftrs, 2)  # Assuming you have 2 classes\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "client_2_model = client_2_model.to(device)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(client_2_model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 2\n",
        "for epoch in range(num_epochs):\n",
        "    client_2_model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = client_2_model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    print(f\"Train Loss client_2_model: {epoch_loss}\")\n",
        "\n",
        "    # Evaluation on validation set\n",
        "    client_2_model.eval()\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = client_2_model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            val_total += labels.size(0)\n",
        "            val_correct += (predicted == labels).sum().item()\n",
        "    val_accuracy = 100 * val_correct / val_total\n",
        "    print(f\"Validation Accuracy client_2_model: {val_accuracy:.2f}%\")\n",
        "\n",
        "# Test the model on the test set\n",
        "client_2_model.eval()\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = client_2_model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        test_total += labels.size(0)\n",
        "        test_correct += (predicted == labels).sum().item()\n",
        "test_accuracy = 100 * test_correct / test_total\n",
        "print(f\"Test Accuracy client_2_model: {test_accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsSZG-5objUz",
        "outputId": "cb67ec47-9e93-485d-96b7-63123ce61067"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/2: 100%|██████████| 22/22 [19:54<00:00, 54.30s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss client_2_model: 0.5302637593951333\n",
            "Validation Accuracy client_2_model: 68.92%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/2: 100%|██████████| 22/22 [00:25<00:00,  1.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss client_2_model: 0.2728493737295238\n",
            "Validation Accuracy client_2_model: 88.51%\n",
            "Test Accuracy client_2_model: 87.58%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Client 3"
      ],
      "metadata": {
        "id": "3425A3tgbPFU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.7 * len(client1_dataset))\n",
        "val_size = int(0.15 * len(client1_dataset))\n",
        "test_size = len(client1_dataset) - train_size - val_size\n",
        "num_epochs = 2\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = random_split(client1_dataset, [train_size, val_size, test_size])\n",
        "\n",
        "# Create DataLoader instances for each set\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "xWW4SG9JbNeD"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client_3_model = models.resnet18(pretrained=True)\n",
        "num_ftrs = client_3_model.fc.in_features\n",
        "client_3_model.fc = nn.Linear(num_ftrs, 2)  # Assuming you have 2 classes\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "client_3_model = client_3_model.to(device)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(client_3_model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 2\n",
        "for epoch in range(num_epochs):\n",
        "    client_3_model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = client_3_model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    print(f\"Train Loss client_3_model: {epoch_loss}\")\n",
        "\n",
        "    # Evaluation on validation set\n",
        "    client_3_model.eval()\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = client_3_model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            val_total += labels.size(0)\n",
        "            val_correct += (predicted == labels).sum().item()\n",
        "    val_accuracy = 100 * val_correct / val_total\n",
        "    print(f\"Validation Accuracy client_3_model: {val_accuracy:.2f}%\")\n",
        "\n",
        "# Test the model on the test set\n",
        "client_3_model.eval()\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = client_3_model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        test_total += labels.size(0)\n",
        "        test_correct += (predicted == labels).sum().item()\n",
        "test_accuracy = 100 * test_correct / test_total\n",
        "print(f\"Test Accuracy client_3_model: {test_accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loljzcPtbkYO",
        "outputId": "3239c2bd-fd23-45d6-b12c-c46b4cf62df1"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/2: 100%|██████████| 22/22 [00:25<00:00,  1.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss client_3_model: 0.47678458569968685\n",
            "Validation Accuracy client_3_model: 76.69%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/2: 100%|██████████| 22/22 [00:25<00:00,  1.16s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss client_3_model: 0.243444893425647\n",
            "Validation Accuracy client_3_model: 83.45%\n",
            "Test Accuracy client_3_model: 87.25%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Client 4"
      ],
      "metadata": {
        "id": "HxZlUTwObR-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.7 * len(client1_dataset))\n",
        "val_size = int(0.15 * len(client1_dataset))\n",
        "test_size = len(client1_dataset) - train_size - val_size\n",
        "num_epochs = 2\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = random_split(client1_dataset, [train_size, val_size, test_size])\n",
        "\n",
        "# Create DataLoader instances for each set\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "YZAYPyfpbONU"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client_4_model = models.resnet18(pretrained=True)\n",
        "num_ftrs = client_4_model.fc.in_features\n",
        "client_4_model.fc = nn.Linear(num_ftrs, 2)  # Assuming you have 2 classes\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "client_4_model = client_4_model.to(device)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(client_4_model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 2\n",
        "for epoch in range(num_epochs):\n",
        "    client_4_model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = client_4_model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    print(f\"Train Loss client_4_model: {epoch_loss}\")\n",
        "\n",
        "    # Evaluation on validation set\n",
        "    client_4_model.eval()\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = client_4_model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            val_total += labels.size(0)\n",
        "            val_correct += (predicted == labels).sum().item()\n",
        "    val_accuracy = 100 * val_correct / val_total\n",
        "    print(f\"Validation Accuracy client_4_model: {val_accuracy:.2f}%\")\n",
        "\n",
        "# Test the model on the test set\n",
        "client_4_model.eval()\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = client_4_model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        test_total += labels.size(0)\n",
        "        test_correct += (predicted == labels).sum().item()\n",
        "test_accuracy = 100 * test_correct / test_total\n",
        "print(f\"Test Accuracy client_4_model: {test_accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dY-OPq-Lbk7K",
        "outputId": "8a3300fc-1981-4d7f-e2f1-52345699eb3f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/2: 100%|██████████| 22/22 [00:25<00:00,  1.16s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss client_4_model: 0.5318356481739687\n",
            "Validation Accuracy client_4_model: 75.68%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/2: 100%|██████████| 22/22 [00:25<00:00,  1.16s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss client_4_model: 0.27034093614126237\n",
            "Validation Accuracy client_4_model: 88.18%\n",
            "Test Accuracy client_4_model: 86.24%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving Model Weights"
      ],
      "metadata": {
        "id": "w1Y4ae1WeGeA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the state_dict of the trained model\n",
        "client_1_model_weights = client_1_model.state_dict()\n",
        "client_2_model_weights = client_2_model.state_dict()\n",
        "client_3_model_weights = client_3_model.state_dict()\n",
        "client_4_model_weights = client_4_model.state_dict()\n",
        "\n",
        "# Save the model weights to a file\n",
        "torch.save(client_1_model_weights, 'client_1_model_weights.pth')\n",
        "torch.save(client_2_model_weights, 'client_2_model_weights.pth')\n",
        "torch.save(client_3_model_weights, 'client_3_model_weights.pth')\n",
        "torch.save(client_4_model_weights, 'client_4_model_weights.pth')\n",
        "\n"
      ],
      "metadata": {
        "id": "Krw2dhTpeJGX"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Weighted Average"
      ],
      "metadata": {
        "id": "lfweO7RXoqpc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weight_client_1 = 0.25\n",
        "weight_client_2 = 0.25\n",
        "weight_client_3 = 0.25\n",
        "weight_client_4 = 0.25\n",
        "\n",
        "# Perform weighted average of the model weights\n",
        "weighted_average_weights = {}\n",
        "for key in client_1_model_weights.keys():\n",
        "    weighted_average_weights[key] = (\n",
        "        weight_client_1 * client_1_model_weights[key] +\n",
        "        weight_client_2 * client_2_model_weights[key] +\n",
        "        weight_client_3 * client_3_model_weights[key] +\n",
        "        weight_client_4 * client_4_model_weights[key]\n",
        "    )\n",
        "\n",
        "# Save the weighted average model weights to a file\n",
        "torch.save(weighted_average_weights, 'weighted_average_model_weights.pth')"
      ],
      "metadata": {
        "id": "4Mu2OcCeensS"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Weighted Averaged model"
      ],
      "metadata": {
        "id": "4FIwcjNGpTw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "weighted_model = copy.deepcopy(client_4_model)\n"
      ],
      "metadata": {
        "id": "FMQDq9lzq6eY"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "weighted_model = weighted_model.to(device)\n",
        "\n",
        "weighted_average_model_weights = torch.load('/content/weighted_average_model_weights.pth')\n",
        "weighted_model.load_state_dict(weighted_average_model_weights)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(weighted_model.parameters(), lr=0.001)\n",
        "\n",
        "# Test the model on the test set\n",
        "weighted_model.eval()\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = weighted_model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        test_total += labels.size(0)\n",
        "        test_correct += (predicted == labels).sum().item()\n",
        "test_accuracy = 100 * test_correct / test_total\n",
        "print(f\"Test Accuracy weighted_model: {test_accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzAzvKIZpTkZ",
        "outputId": "4c94fefc-b3bd-42e7-f304-54a21d74ef1b"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy weighted_model: 67.11%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normalized weighted scheme"
      ],
      "metadata": {
        "id": "CWZId9UgsVFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation accuracies of each client model\n",
        "validation_accuracies = {\n",
        "    'client_1_model': 85.47,\n",
        "    'client_2_model': 88.51,\n",
        "    'client_3_model': 83.45,\n",
        "    'client_4_model': 88.18\n",
        "}\n",
        "\n",
        "# Normalize validation accuracies\n",
        "total_accuracy = sum(validation_accuracies.values())\n",
        "normalized_accuracies = {client: accuracy / total_accuracy for client, accuracy in validation_accuracies.items()}\n",
        "\n",
        "# Assign weights based on normalized accuracies\n",
        "weights = {client: normalized_accuracy for client, normalized_accuracy in normalized_accuracies.items()}\n",
        "\n",
        "print(\"Weighting Scheme:\")\n",
        "for client, weight in weights.items():\n",
        "    print(f\"{client}: {weight:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpZmun-ssXz6",
        "outputId": "f709dd59-5840-4f59-e139-15cde42cdbad"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weighting Scheme:\n",
            "client_1_model: 0.25\n",
            "client_2_model: 0.26\n",
            "client_3_model: 0.24\n",
            "client_4_model: 0.26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weight_client_1_normalized_validation = 0.25\n",
        "weight_client_2_normalized_validation = 0.26\n",
        "weight_client_3_normalized_validation = 0.24\n",
        "weight_client_4_normalized_validation = 0.26\n",
        "\n",
        "weighted_average_weights = {}\n",
        "for key in client_1_model_weights.keys():\n",
        "    weighted_average_weights[key] = (\n",
        "        weight_client_1_normalized_validation * client_1_model_weights[key] +\n",
        "        weight_client_2_normalized_validation * client_2_model_weights[key] +\n",
        "        weight_client_3_normalized_validation * client_3_model_weights[key] +\n",
        "        weight_client_4_normalized_validation * client_4_model_weights[key]\n",
        "    )\n",
        "\n",
        "# Save the weighted average model weights to a file\n",
        "torch.save(weighted_average_weights, 'Normalized_validation_weighted_average_model_weights.pth')"
      ],
      "metadata": {
        "id": "ZGBEMuFGsha-"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Weighted Model - Normalized Validation scheme for weights"
      ],
      "metadata": {
        "id": "3oLDlP_Ttd05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weighted_model_NV = copy.deepcopy(client_4_model)"
      ],
      "metadata": {
        "id": "vD_r4mBStjjm"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "weighted_model_NV = weighted_model_NV.to(device)\n",
        "\n",
        "weighted_average_model_weights = torch.load('/content/Normalized_validation_weighted_average_model_weights.pth')\n",
        "weighted_model_NV.load_state_dict(weighted_average_model_weights)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(weighted_model_NV.parameters(), lr=0.001)\n",
        "\n",
        "# Test the model on the test set\n",
        "weighted_model_NV.eval()\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = weighted_model_NV(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        test_total += labels.size(0)\n",
        "        test_correct += (predicted == labels).sum().item()\n",
        "test_accuracy = 100 * test_correct / test_total\n",
        "print(f\"Test Accuracy weighted_model_NV: {test_accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoX8fcEdtn15",
        "outputId": "29ed7dc6-fe56-4494-f071-bc2f83336c8f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy weighted_model_NV: 67.11%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil"
      ],
      "metadata": {
        "id": "xC9yZyI-xo6H"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "source_path = '/content/Normalized_validation_weighted_average_model_weights.pth'\n",
        "destination_path = '/content/drive/MyDrive/Thesis/'\n",
        "shutil.move(source_path, destination_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "C6YerhvKxp_q",
        "outputId": "b9d58727-d5a4-4960-fb43-cc47ee31f01b"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Thesis/Normalized_validation_weighted_average_model_weights.pth'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8WMefbXGx3it"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1HG4UjxIAw1bJh7ekGvvkEqJC4DxBfJYU",
      "authorship_tag": "ABX9TyNmYnlgdTN+XMFx+TfbAh/G",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}