{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krish-navulla/FL_Breast_Cancer_Classification/blob/main/Thesis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zDyF5NnDo3VZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torchvision.io import read_image\n",
        "from torch.utils.data import DataLoader, random_split, Dataset\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "from tqdm import tqdm\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elxgdVchCFpa"
      },
      "source": [
        "# Creating pytorch data loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_-BfP0eB8as"
      },
      "source": [
        "# Creating annotations file and client datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image\n",
        "from torch.utils.data import DataLoader, random_split, Dataset\n",
        "from torchvision import transforms\n",
        "\n",
        "annotations_benign = pd.read_csv(\"/content/drive/MyDrive/Thesis/BreaKHis_v1/histology_slides/breast/annotations_benign.txt\", delimiter='\\t')\n",
        "annotations_malignant = pd.read_csv(\"/content/drive/MyDrive/Thesis/BreaKHis_v1/histology_slides/breast/annotations_malignant.txt\", delimiter='\\t')\n",
        "\n",
        "annotations = pd.concat([pd.DataFrame(annotations_malignant, columns=['name', 'value']), pd.DataFrame(annotations_benign, columns=['name', 'value'])])\n",
        "\n",
        "annotations = annotations.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "class CustomImageDataset():\n",
        "    def __init__(self, annotations_file, img_dir, transform, split_ratios, target_transform=None):\n",
        "        self.img_labels = annotations_file.reset_index(drop=True)\n",
        "        print(f\"Length of DataFrame: {len(self.img_labels)}\")  # Print the length of the DataFrame\n",
        "        print(f\"Sample of DataFrame:\\n{self.img_labels.head()}\")  # Print a sample of the DataFrame\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.split_ratios = split_ratios\n",
        "\n",
        "        # Split the dataset into subsets for each client\n",
        "        self._split_dataset()\n",
        "\n",
        "    def _split_dataset(self):\n",
        "        if self.split_ratios is None:\n",
        "            raise ValueError(\"split_ratios cannot be None\")\n",
        "\n",
        "        # Calculate the sizes of the splits for each client\n",
        "        split_sizes = [int(len(self.img_labels) * ratio) for ratio in self.split_ratios]\n",
        "\n",
        "        # Split the dataset into subsets for each client\n",
        "        self.datasets = []\n",
        "        start_idx = 0\n",
        "        for size in split_sizes:\n",
        "            subset = self.img_labels.iloc[start_idx:start_idx + size]\n",
        "            self.datasets.append(subset)\n",
        "            start_idx += size\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    # def __getitem__(self, idx):\n",
        "    #     if idx >= len(self.img_labels):\n",
        "    #         raise IndexError(f\"Index {idx} is out of range for the dataset\")\n",
        "    #     img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0]).replace(\"\\\\\",\"/\")\n",
        "    #     image = Image.open(img_path).convert('RGB')\n",
        "    #     label = self.img_labels.iloc[idx, 1]\n",
        "    #     if self.transform:\n",
        "    #         image = self.transform(image)\n",
        "    #     if self.target_transform:\n",
        "    #         label = self.target_transform(label)\n",
        "    #     return image, label\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0]).replace(\"\\\\\",\"/\")\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "            label = self.img_labels.iloc[idx, 1]\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            if self.target_transform:\n",
        "                label = self.target_transform(label)\n",
        "            return image, label\n",
        "        except KeyError as e:\n",
        "            print(f\"KeyError: {e}\")\n",
        "            print(f\"Index: {idx}, Length of DataFrame: {len(self.img_labels)}\")\n",
        "            raise e\n",
        "        except IndexError as e:\n",
        "            print(f\"IndexError: {e}\")\n",
        "            print(f\"Index: {idx}, Length of DataFrame: {len(self.img_labels)}\")\n",
        "            raise e\n",
        "\n",
        "\n",
        "# Define split ratios for each client\n",
        "split_ratios = [0.25, 0.25, 0.25, 0.25]  # Adjust the split ratios as needed\n",
        "\n",
        "img_dir = \"\\content\\drive\\MyDrive\\Thesis\\BreaKHis_v1\"\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Adjust the size as needed\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "dataset = CustomImageDataset(\n",
        "    img_dir=img_dir,\n",
        "    annotations_file=annotations,\n",
        "    transform=transform,\n",
        "    split_ratios=split_ratios\n",
        ")\n",
        "\n",
        "# Access datasets for each client\n",
        "client_datasets =dataset.datasets\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "ebnvoneKCAhq",
        "outputId": "6037e999-d031-4e23-8401-40d176675304"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "non-default argument follows default argument (<ipython-input-17-d018823f0639>, line 8)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-d018823f0639>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    def __init__(self, annotations_file, img_dir, transform, target_transform=None, split_ratios):\u001b[0m\n\u001b[0m                                                                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m non-default argument follows default argument\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# client_datasets = {'client_1': client_datasets[0].reset_index(drop=True), 'client_2': client_datasets[1].reset_index(drop=True), 'client_3': client_datasets[2].reset_index(drop=True), 'client_4': client_datasets[3].reset_index(drop=True)}\n",
        "client_datasets = {'client_1': client_datasets[0], 'client_2': client_datasets[1], 'client_3': client_datasets[2], 'client_4': client_datasets[3]}"
      ],
      "metadata": {
        "id": "w8DbKa6ACD61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wc4kBHWCRR1"
      },
      "source": [
        "# Test model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjR_mlCaNH-N"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-FzXgOE6iu7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Client 1"
      ],
      "metadata": {
        "id": "_t9G_NbrW_Vd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.7 * len(client1_dataset))\n",
        "val_size = int(0.15 * len(client1_dataset))\n",
        "test_size = len(client1_dataset) - train_size - val_size\n",
        "num_epochs = 2\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = random_split(client1_dataset, [train_size, val_size, test_size])\n",
        "\n",
        "# Create DataLoader instances for each set\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "2X5se5TdXDAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCYFBQSdDe6y",
        "outputId": "c4637dd2-032d-416f-b578-e67384ff55af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Epoch 1/2: 100%|██████████| 22/22 [19:50<00:00, 54.10s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.5510490213023177\n",
            "Validation Accuracy: 71.62%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/2: 100%|██████████| 22/22 [00:25<00:00,  1.16s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.30845355926134066\n",
            "Validation Accuracy: 85.47%\n",
            "Test Accuracy: 87.58%\n"
          ]
        }
      ],
      "source": [
        "client_1_model = models.resnet18(pretrained=True)\n",
        "num_ftrs = client_1_model.fc.in_features\n",
        "client_1_model.fc = nn.Linear(num_ftrs, 2)  # Assuming you have 2 classes\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "client_1_model = client_1_model.to(device)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(client_1_model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 2\n",
        "for epoch in range(num_epochs):\n",
        "    client_1_model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = client_1_model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    print(f\"Train Loss: {epoch_loss}\")\n",
        "\n",
        "    # Evaluation on validation set\n",
        "    client_1_model.eval()\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = client_1_model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            val_total += labels.size(0)\n",
        "            val_correct += (predicted == labels).sum().item()\n",
        "    val_accuracy = 100 * val_correct / val_total\n",
        "    print(f\"Validation Accuracy: {val_accuracy:.2f}%\")\n",
        "\n",
        "# Test the model on the test set\n",
        "client_1_model.eval()\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = client_1_model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        test_total += labels.size(0)\n",
        "        test_correct += (predicted == labels).sum().item()\n",
        "test_accuracy = 100 * test_correct / test_total\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Client 2"
      ],
      "metadata": {
        "id": "6AWlwm7lbKZC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-b2sSS8gqKan"
      },
      "outputs": [],
      "source": [
        "train_size = int(0.7 * len(client2_dataset))\n",
        "val_size = int(0.15 * len(client2_dataset))\n",
        "test_size = len(client2_dataset) - train_size - val_size\n",
        "num_epochs = 2\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = random_split(client2_dataset, [train_size, val_size, test_size])\n",
        "\n",
        "# Create DataLoader instances for each set\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client_2_model = models.resnet18(pretrained=True)\n",
        "num_ftrs = client_2_model.fc.in_features\n",
        "client_2_model.fc = nn.Linear(num_ftrs, 2)  # Assuming you have 2 classes\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "client_2_model = client_2_model.to(device)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(client_2_model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 2\n",
        "for epoch in range(num_epochs):\n",
        "    client_2_model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = client_2_model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    print(f\"Train Loss client_2_model: {epoch_loss}\")\n",
        "\n",
        "    # Evaluation on validation set\n",
        "    client_2_model.eval()\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = client_2_model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            val_total += labels.size(0)\n",
        "            val_correct += (predicted == labels).sum().item()\n",
        "    val_accuracy = 100 * val_correct / val_total\n",
        "    print(f\"Validation Accuracy client_2_model: {val_accuracy:.2f}%\")\n",
        "\n",
        "# Test the model on the test set\n",
        "client_2_model.eval()\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = client_2_model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        test_total += labels.size(0)\n",
        "        test_correct += (predicted == labels).sum().item()\n",
        "test_accuracy = 100 * test_correct / test_total\n",
        "print(f\"Test Accuracy client_2_model: {test_accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsSZG-5objUz",
        "outputId": "cb67ec47-9e93-485d-96b7-63123ce61067"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/2: 100%|██████████| 22/22 [19:54<00:00, 54.30s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss client_2_model: 0.5302637593951333\n",
            "Validation Accuracy client_2_model: 68.92%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/2: 100%|██████████| 22/22 [00:25<00:00,  1.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss client_2_model: 0.2728493737295238\n",
            "Validation Accuracy client_2_model: 88.51%\n",
            "Test Accuracy client_2_model: 87.58%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Client 3"
      ],
      "metadata": {
        "id": "3425A3tgbPFU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.7 * len(client1_dataset))\n",
        "val_size = int(0.15 * len(client1_dataset))\n",
        "test_size = len(client1_dataset) - train_size - val_size\n",
        "num_epochs = 2\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = random_split(client1_dataset, [train_size, val_size, test_size])\n",
        "\n",
        "# Create DataLoader instances for each set\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "xWW4SG9JbNeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client_3_model = models.resnet18(pretrained=True)\n",
        "num_ftrs = client_3_model.fc.in_features\n",
        "client_3_model.fc = nn.Linear(num_ftrs, 2)  # Assuming you have 2 classes\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "client_3_model = client_3_model.to(device)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(client_3_model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 2\n",
        "for epoch in range(num_epochs):\n",
        "    client_3_model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = client_3_model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    print(f\"Train Loss client_3_model: {epoch_loss}\")\n",
        "\n",
        "    # Evaluation on validation set\n",
        "    client_3_model.eval()\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = client_3_model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            val_total += labels.size(0)\n",
        "            val_correct += (predicted == labels).sum().item()\n",
        "    val_accuracy = 100 * val_correct / val_total\n",
        "    print(f\"Validation Accuracy client_3_model: {val_accuracy:.2f}%\")\n",
        "\n",
        "# Test the model on the test set\n",
        "client_3_model.eval()\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = client_3_model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        test_total += labels.size(0)\n",
        "        test_correct += (predicted == labels).sum().item()\n",
        "test_accuracy = 100 * test_correct / test_total\n",
        "print(f\"Test Accuracy client_3_model: {test_accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loljzcPtbkYO",
        "outputId": "3239c2bd-fd23-45d6-b12c-c46b4cf62df1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/2: 100%|██████████| 22/22 [00:25<00:00,  1.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss client_3_model: 0.47678458569968685\n",
            "Validation Accuracy client_3_model: 76.69%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/2: 100%|██████████| 22/22 [00:25<00:00,  1.16s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss client_3_model: 0.243444893425647\n",
            "Validation Accuracy client_3_model: 83.45%\n",
            "Test Accuracy client_3_model: 87.25%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Client 4"
      ],
      "metadata": {
        "id": "HxZlUTwObR-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.7 * len(client1_dataset))\n",
        "val_size = int(0.15 * len(client1_dataset))\n",
        "test_size = len(client1_dataset) - train_size - val_size\n",
        "num_epochs = 2\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = random_split(client1_dataset, [train_size, val_size, test_size])\n",
        "\n",
        "# Create DataLoader instances for each set\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "YZAYPyfpbONU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client_4_model = models.resnet18(pretrained=True)\n",
        "num_ftrs = client_4_model.fc.in_features\n",
        "client_4_model.fc = nn.Linear(num_ftrs, 2)  # Assuming you have 2 classes\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "client_4_model = client_4_model.to(device)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(client_4_model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 2\n",
        "for epoch in range(num_epochs):\n",
        "    client_4_model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = client_4_model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    print(f\"Train Loss client_4_model: {epoch_loss}\")\n",
        "\n",
        "    # Evaluation on validation set\n",
        "    client_4_model.eval()\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = client_4_model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            val_total += labels.size(0)\n",
        "            val_correct += (predicted == labels).sum().item()\n",
        "    val_accuracy = 100 * val_correct / val_total\n",
        "    print(f\"Validation Accuracy client_4_model: {val_accuracy:.2f}%\")\n",
        "\n",
        "# Test the model on the test set\n",
        "client_4_model.eval()\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = client_4_model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        test_total += labels.size(0)\n",
        "        test_correct += (predicted == labels).sum().item()\n",
        "test_accuracy = 100 * test_correct / test_total\n",
        "print(f\"Test Accuracy client_4_model: {test_accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dY-OPq-Lbk7K",
        "outputId": "8a3300fc-1981-4d7f-e2f1-52345699eb3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/2: 100%|██████████| 22/22 [00:25<00:00,  1.16s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss client_4_model: 0.5318356481739687\n",
            "Validation Accuracy client_4_model: 75.68%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/2: 100%|██████████| 22/22 [00:25<00:00,  1.16s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss client_4_model: 0.27034093614126237\n",
            "Validation Accuracy client_4_model: 88.18%\n",
            "Test Accuracy client_4_model: 86.24%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving Model Weights"
      ],
      "metadata": {
        "id": "w1Y4ae1WeGeA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the state_dict of the trained model\n",
        "client_1_model_weights = client_1_model.state_dict()\n",
        "client_2_model_weights = client_2_model.state_dict()\n",
        "client_3_model_weights = client_3_model.state_dict()\n",
        "client_4_model_weights = client_4_model.state_dict()\n",
        "\n",
        "# Save the model weights to a file\n",
        "torch.save(client_1_model_weights, 'client_1_model_weights.pth')\n",
        "torch.save(client_2_model_weights, 'client_2_model_weights.pth')\n",
        "torch.save(client_3_model_weights, 'client_3_model_weights.pth')\n",
        "torch.save(client_4_model_weights, 'client_4_model_weights.pth')\n",
        "\n"
      ],
      "metadata": {
        "id": "Krw2dhTpeJGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Weighted Average"
      ],
      "metadata": {
        "id": "lfweO7RXoqpc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weight_client_1 = 0.25\n",
        "weight_client_2 = 0.25\n",
        "weight_client_3 = 0.25\n",
        "weight_client_4 = 0.25\n",
        "\n",
        "# Perform weighted average of the model weights\n",
        "weighted_average_weights = {}\n",
        "for key in client_1_model_weights.keys():\n",
        "    weighted_average_weights[key] = (\n",
        "        weight_client_1 * client_1_model_weights[key] +\n",
        "        weight_client_2 * client_2_model_weights[key] +\n",
        "        weight_client_3 * client_3_model_weights[key] +\n",
        "        weight_client_4 * client_4_model_weights[key]\n",
        "    )\n",
        "\n",
        "# Save the weighted average model weights to a file\n",
        "torch.save(weighted_average_weights, 'weighted_average_model_weights.pth')"
      ],
      "metadata": {
        "id": "4Mu2OcCeensS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Weighted Averaged model"
      ],
      "metadata": {
        "id": "4FIwcjNGpTw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "weighted_model = copy.deepcopy(client_4_model)\n"
      ],
      "metadata": {
        "id": "FMQDq9lzq6eY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "weighted_model = weighted_model.to(device)\n",
        "\n",
        "weighted_average_model_weights = torch.load('/content/weighted_average_model_weights.pth')\n",
        "weighted_model.load_state_dict(weighted_average_model_weights)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(weighted_model.parameters(), lr=0.001)\n",
        "\n",
        "# Test the model on the test set\n",
        "weighted_model.eval()\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = weighted_model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        test_total += labels.size(0)\n",
        "        test_correct += (predicted == labels).sum().item()\n",
        "test_accuracy = 100 * test_correct / test_total\n",
        "print(f\"Test Accuracy weighted_model: {test_accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzAzvKIZpTkZ",
        "outputId": "4c94fefc-b3bd-42e7-f304-54a21d74ef1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy weighted_model: 67.11%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normalized weighted scheme"
      ],
      "metadata": {
        "id": "CWZId9UgsVFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation accuracies of each client model\n",
        "validation_accuracies = {\n",
        "    'client_1_model': 85.47,\n",
        "    'client_2_model': 88.51,\n",
        "    'client_3_model': 83.45,\n",
        "    'client_4_model': 88.18\n",
        "}\n",
        "\n",
        "# Normalize validation accuracies\n",
        "total_accuracy = sum(validation_accuracies.values())\n",
        "normalized_accuracies = {client: accuracy / total_accuracy for client, accuracy in validation_accuracies.items()}\n",
        "\n",
        "# Assign weights based on normalized accuracies\n",
        "weights = {client: normalized_accuracy for client, normalized_accuracy in normalized_accuracies.items()}\n",
        "\n",
        "print(\"Weighting Scheme:\")\n",
        "for client, weight in weights.items():\n",
        "    print(f\"{client}: {weight:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpZmun-ssXz6",
        "outputId": "f709dd59-5840-4f59-e139-15cde42cdbad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weighting Scheme:\n",
            "client_1_model: 0.25\n",
            "client_2_model: 0.26\n",
            "client_3_model: 0.24\n",
            "client_4_model: 0.26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weight_client_1_normalized_validation = 0.25\n",
        "weight_client_2_normalized_validation = 0.26\n",
        "weight_client_3_normalized_validation = 0.24\n",
        "weight_client_4_normalized_validation = 0.26\n",
        "\n",
        "weighted_average_weights = {}\n",
        "for key in client_1_model_weights.keys():\n",
        "    weighted_average_weights[key] = (\n",
        "        weight_client_1_normalized_validation * client_1_model_weights[key] +\n",
        "        weight_client_2_normalized_validation * client_2_model_weights[key] +\n",
        "        weight_client_3_normalized_validation * client_3_model_weights[key] +\n",
        "        weight_client_4_normalized_validation * client_4_model_weights[key]\n",
        "    )\n",
        "\n",
        "# Save the weighted average model weights to a file\n",
        "torch.save(weighted_average_weights, 'Normalized_validation_weighted_average_model_weights.pth')"
      ],
      "metadata": {
        "id": "ZGBEMuFGsha-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Weighted Model - Normalized Validation scheme for weights"
      ],
      "metadata": {
        "id": "3oLDlP_Ttd05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weighted_model_NV = copy.deepcopy(client_4_model)"
      ],
      "metadata": {
        "id": "vD_r4mBStjjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "weighted_model_NV = weighted_model_NV.to(device)\n",
        "\n",
        "weighted_average_model_weights = torch.load('/content/Normalized_validation_weighted_average_model_weights.pth')\n",
        "weighted_model_NV.load_state_dict(weighted_average_model_weights)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(weighted_model_NV.parameters(), lr=0.001)\n",
        "\n",
        "# Test the model on the test set\n",
        "weighted_model_NV.eval()\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = weighted_model_NV(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        test_total += labels.size(0)\n",
        "        test_correct += (predicted == labels).sum().item()\n",
        "test_accuracy = 100 * test_correct / test_total\n",
        "print(f\"Test Accuracy weighted_model_NV: {test_accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoX8fcEdtn15",
        "outputId": "29ed7dc6-fe56-4494-f071-bc2f83336c8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy weighted_model_NV: 67.11%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil"
      ],
      "metadata": {
        "id": "xC9yZyI-xo6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "source_path = '/content/Normalized_validation_weighted_average_model_weights.pth'\n",
        "destination_path = '/content/drive/MyDrive/Thesis/'\n",
        "shutil.move(source_path, destination_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "C6YerhvKxp_q",
        "outputId": "b9d58727-d5a4-4960-fb43-cc47ee31f01b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Thesis/Normalized_validation_weighted_average_model_weights.pth'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8WMefbXGx3it"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FL Cyles = 4"
      ],
      "metadata": {
        "id": "Fk5sOccIlCRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Method definations"
      ],
      "metadata": {
        "id": "DYJFE5U016sG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, dataset, batch_size,model_name, num_epochs=2, device=\"cpu\", test_only = False):\n",
        "\n",
        "    train_size = int(0.7 * len(dataset))\n",
        "    val_size = int(0.15 * len(dataset))\n",
        "    test_size = len(dataset) - train_size - val_size\n",
        "\n",
        "    # Split the dataset\n",
        "    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "    # Create DataLoader instances for each set\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Define the optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = nn.Linear(num_ftrs, 2)  # Assuming you have 2 classes\n",
        "\n",
        "    if test_only:\n",
        "      model.to(device)\n",
        "      model.eval()\n",
        "      test_correct = 0\n",
        "      test_total = 0\n",
        "      with torch.no_grad():\n",
        "          for images, labels in test_loader:\n",
        "              images, labels = images.to(device), labels.to(device)\n",
        "              outputs = model(images)\n",
        "              _, predicted = torch.max(outputs, 1)\n",
        "              test_total += labels.size(0)\n",
        "              test_correct += (predicted == labels).sum().item()\n",
        "      test_accuracy = 100 * test_correct / test_total\n",
        "      # print(f\"Test Accuracy {model_name} : {test_accuracy:.2f}%\")\n",
        "      return test_accuracy\n",
        "\n",
        "    else:\n",
        "    # Training loop\n",
        "      model = model.to(device)\n",
        "      for epoch in range(num_epochs):\n",
        "          model.train()\n",
        "          running_loss = 0.0\n",
        "          for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "              images, labels = images.to(device), labels.to(device)\n",
        "              optimizer.zero_grad()\n",
        "              outputs = model(images)\n",
        "              loss = criterion(outputs, labels)\n",
        "              loss.backward()\n",
        "              optimizer.step()\n",
        "              running_loss += loss.item() * images.size(0)\n",
        "          epoch_loss = running_loss / len(train_loader.dataset)\n",
        "          print(f\"Train Loss {model_name} : {epoch_loss}\")\n",
        "\n",
        "          # Evaluation on validation set\n",
        "          model.eval()\n",
        "          val_correct = 0\n",
        "          val_total = 0\n",
        "          with torch.no_grad():\n",
        "              for images, labels in val_loader:\n",
        "                  images, labels = images.to(device), labels.to(device)\n",
        "                  outputs = model(images)\n",
        "                  _, predicted = torch.max(outputs, 1)\n",
        "                  val_total += labels.size(0)\n",
        "                  val_correct += (predicted == labels).sum().item()\n",
        "          val_accuracy = 100 * val_correct / val_total\n",
        "          print(f\"Validation Accuracy {model_name} : {val_accuracy:.2f}%\")\n",
        "\n",
        "      # Test the model on the test set\n",
        "      model.eval()\n",
        "      test_correct = 0\n",
        "      test_total = 0\n",
        "      with torch.no_grad():\n",
        "          for images, labels in test_loader:\n",
        "              images, labels = images.to(device), labels.to(device)\n",
        "              outputs = model(images)\n",
        "              _, predicted = torch.max(outputs, 1)\n",
        "              test_total += labels.size(0)\n",
        "              test_correct += (predicted == labels).sum().item()\n",
        "      test_accuracy = 100 * test_correct / test_total\n",
        "      print(f\"Test Accuracy {model_name} : {test_accuracy:.2f}%\")\n",
        "\n",
        "      torch.save(model.state_dict(), f\"{model_name}_model_weights.pth\")\n",
        "\n",
        "\n",
        "\n",
        "def compute_weighted_average_model(model_names, weights, cycle_number):\n",
        "    # Load the saved model weights\n",
        "    client_model_weights = {}\n",
        "    for model_name in model_names:\n",
        "        client_model_weights[model_name] = torch.load(f'{model_name}_model_weights.pth')\n",
        "\n",
        "    # Perform weighted average of the model weights\n",
        "    weighted_average_weights = {}\n",
        "    for key in client_model_weights[model_names[0]].keys():\n",
        "        weighted_average_weights[key] = sum(weights[model_name] * client_model_weights[model_name][key] for model_name in model_names)\n",
        "\n",
        "    # Save the weighted average weights to a file\n",
        "    torch.save(weighted_average_weights, f'weighted_average_model_weights_cycle_{cycle_number}.pth')\n",
        "\n",
        "\n",
        "\n",
        "model_names = ['client_1', 'client_2', 'client_3', 'client_4']\n",
        "weights = {'client_1': 0.25, 'client_2': 0.25, 'client_3': 0.25, 'client_4': 0.25}\n",
        "\n",
        "\n",
        "def federated_learning(num_cycles,model_names, weights, num_epochs=2, batch_size=64):\n",
        "\n",
        "  for i in range(num_cycles):\n",
        "    if i == 0:\n",
        "      weighted_average_weights = torch.load(\"/content/drive/MyDrive/Thesis/weighted_average_model_weights.pth\")\n",
        "    else:\n",
        "      weighted_average_weights = torch.load(f'weighted_average_model_weights_cycle_{i}.pth')\n",
        "    print(f\"Federated Learning Cycle {i+1}\")\n",
        "    for model_name in model_names:\n",
        "      print(f\"Training {model_name} model\")\n",
        "      model = models.resnet18(pretrained=True)\n",
        "      num_ftrs = model.fc.in_features\n",
        "      model.fc = nn.Linear(num_ftrs, 2)  # Assuming you have 2 classes\n",
        "      model.load_state_dict(weighted_average_weights)\n",
        "      train_model(model, client_datasets[model_name], batch_size, model_name = model_name, num_epochs=0, device=\"cpu\",test_only=False )\n",
        "\n",
        "    compute_weighted_average_model(model_names, weights, cycle_number = i)\n",
        "    print(\"Weighted average model weights computed\")\n",
        "\n",
        "    print(f\"Testing FL model\")\n",
        "    model = models.resnet18(pretrained=True)\n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = nn.Linear(num_ftrs, 2)  # Assuming you have 2 classes\n",
        "    model.load_state_dict(f'weighted_average_model_weights_cycle_{i}.pth')\n",
        "    train_model(model, client_datasets['client_1'], batch_size, model_name = model_name, num_epochs=2, device=\"cpu\",test_only=True )\n",
        "\n",
        "\n",
        "federated_learning(2, model_names, weights, num_epochs=2, batch_size=64)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "17o4LnZ3myMS",
        "outputId": "74d063b8-7c1d-431d-ac16-ea31a1f29b26"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Federated Learning Cycle 1\n",
            "Training client_1 model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:01<00:00, 27.3MB/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "1413",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3653\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 1413",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-8926d30a9b78>\u001b[0m in \u001b[0;36m<cell line: 134>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m \u001b[0mfederated_learning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-8926d30a9b78>\u001b[0m in \u001b[0;36mfederated_learning\u001b[0;34m(num_cycles, model_names, weights, num_epochs, batch_size)\u001b[0m\n\u001b[1;32m    119\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_ftrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Assuming you have 2 classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweighted_average_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m       \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0mcompute_weighted_average_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-8926d30a9b78>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataset, batch_size, model_name, num_epochs, device, test_only)\u001b[0m\n\u001b[1;32m     72\u001b[0m       \u001b[0mtest_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m               \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m               \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3761\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3762\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3763\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3655\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3656\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3657\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 1413"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1"
      ],
      "metadata": {
        "id": "1wN2_t3PdB11"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "from PIL import Image\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.DEBUG)\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "        self.img_labels = annotations_file.reset_index(drop=True)\n",
        "        logging.debug(f\"Initial dataset length: {len(self.img_labels)}\")\n",
        "        logging.debug(f\"Sample of DataFrame:\\n{self.img_labels.head()}\")\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            if idx >= len(self.img_labels):\n",
        "                raise IndexError(f\"Index {idx} is out of range for the dataset\")\n",
        "\n",
        "            img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0]).replace(\"\\\\\", \"/\")\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "            label = self.img_labels.iloc[idx, 1]\n",
        "\n",
        "            logging.debug(f\"Loading image at {img_path}, label: {label}\")\n",
        "\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            if self.target_transform:\n",
        "                label = self.target_transform(label)\n",
        "\n",
        "            return image, label\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error loading data at index {idx}: {e}\")\n",
        "            raise e\n",
        "\n",
        "# Function to split dataset into clients\n",
        "def split_dataset(annotations, split_ratios):\n",
        "    total_length = len(annotations)\n",
        "    split_indices = [int(ratio * total_length) for ratio in split_ratios]\n",
        "\n",
        "    datasets = []\n",
        "    start_idx = 0\n",
        "    for size in split_indices:\n",
        "        datasets.append(annotations.iloc[start_idx:start_idx + size].reset_index(drop=True))\n",
        "        start_idx += size\n",
        "\n",
        "    return datasets\n",
        "\n",
        "def train_model(model, dataset, batch_size, model_name, num_epochs, device=\"cuda\", test_only=False):\n",
        "    train_size = int(0.7 * len(dataset))\n",
        "    val_size = int(0.15 * len(dataset))\n",
        "    test_size = len(dataset) - train_size - val_size\n",
        "\n",
        "    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "    logging.debug(f\"Train size: {train_size}, Val size: {val_size}, Test size: {test_size}\")\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "    if test_only:\n",
        "        model.to(device)\n",
        "        model.eval()\n",
        "        test_correct = 0\n",
        "        test_total = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                test_total += labels.size(0)\n",
        "                test_correct += (predicted == labels).sum().item()\n",
        "        test_accuracy = 100 * test_correct / test_total\n",
        "\n",
        "        return test_accuracy\n",
        "    else:\n",
        "        model = model.to(device)\n",
        "        for epoch in range(num_epochs):\n",
        "            model.train()\n",
        "            running_loss = 0.0\n",
        "            for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                running_loss += loss.item() * images.size(0)\n",
        "            epoch_loss = running_loss / len(train_loader.dataset)\n",
        "            print(f\"Train Loss {model_name}: {epoch_loss}\")\n",
        "\n",
        "            model.eval()\n",
        "            val_correct = 0\n",
        "            val_total = 0\n",
        "            with torch.no_grad():\n",
        "                for images, labels in val_loader:\n",
        "                    images, labels = images.to(device), labels.to(device)\n",
        "                    outputs = model(images)\n",
        "                    _, predicted = torch.max(outputs, 1)\n",
        "                    val_total += labels.size(0)\n",
        "                    val_correct += (predicted == labels).sum().item()\n",
        "            val_accuracy = 100 * val_correct / val_total\n",
        "            print(f\"Validation Accuracy {model_name}: {val_accuracy:.2f}%\")\n",
        "\n",
        "        model.eval()\n",
        "        test_correct = 0\n",
        "        test_total = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                test_total += labels.size(0)\n",
        "                test_correct += (predicted == labels).sum().item()\n",
        "        test_accuracy = 100 * test_correct / test_total\n",
        "        print(f\"Test Accuracy {model_name}: {test_accuracy:.2f}%\")\n",
        "\n",
        "        torch.save(model.state_dict(), f\"{model_name}_model_weights.pth\")\n",
        "\n",
        "\n",
        "def compute_weighted_average_model(model_names, weights, cycle_number):\n",
        "    # Load the saved model weights\n",
        "    client_model_weights = {}\n",
        "    for model_name in model_names:\n",
        "        client_model_weights[model_name] = torch.load(f'{model_name}_model_weights.pth')\n",
        "\n",
        "    # Perform weighted average of the model weights\n",
        "    weighted_average_weights = {}\n",
        "    for key in client_model_weights[model_names[0]].keys():\n",
        "        weighted_average_weights[key] = sum(weights[model_name] * client_model_weights[model_name][key] for model_name in model_names)\n",
        "\n",
        "    # Save the weighted average weights to a file\n",
        "    torch.save(weighted_average_weights, f'weighted_average_model_weights_cycle_{cycle_number}.pth')\n",
        "\n",
        "\n",
        "annotations_benign = pd.read_csv(\"/content/drive/MyDrive/Thesis/BreaKHis_v1/histology_slides/breast/annotations_benign.txt\", delimiter='\\t')\n",
        "annotations_malignant = pd.read_csv(\"/content/drive/MyDrive/Thesis/BreaKHis_v1/histology_slides/breast/annotations_malignant.txt\", delimiter='\\t')\n",
        "\n",
        "annotations = pd.concat([pd.DataFrame(annotations_malignant, columns=['name', 'value']), pd.DataFrame(annotations_benign, columns=['name', 'value'])])\n",
        "\n",
        "annotations = annotations.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "split_ratios = [0.25, 0.25, 0.25, 0.25]\n",
        "img_dir = \"/content/drive/MyDrive/Thesis/BreaKHis_v1\"\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Split dataset into client datasets\n",
        "client_datasets_dataframes = split_dataset(annotations, split_ratios)\n",
        "client_datasets = {}\n",
        "for i, df in enumerate(client_datasets_dataframes):\n",
        "    client_datasets[f'client_{i+1}'] = CustomImageDataset(df, img_dir, transform=transform)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model_names = ['client_1', 'client_2', 'client_3', 'client_4']\n",
        "weights = {'client_1': 0.25, 'client_2': 0.25, 'client_3': 0.25, 'client_4': 0.25}\n",
        "\n",
        "\n",
        "def federated_learning(num_cycles,model_names, weights, num_epochs=2, batch_size=64):\n",
        "\n",
        "  for i in range(num_cycles):\n",
        "    if i == 0:\n",
        "      weighted_average_weights = torch.load(\"/content/drive/MyDrive/Thesis/weighted_average_model_weights.pth\")\n",
        "    else:\n",
        "      weighted_average_weights = torch.load(f'weighted_average_model_weights_cycle_{i}.pth')\n",
        "    print(f\"Federated Learning Cycle {i+1}\")\n",
        "    for model_name in model_names:\n",
        "      print(f\"Training {model_name} model\")\n",
        "      model = models.resnet18(pretrained=True)\n",
        "      num_ftrs = model.fc.in_features\n",
        "      model.fc = nn.Linear(num_ftrs, 2)  # Assuming you have 2 classes\n",
        "      model.load_state_dict(weighted_average_weights)\n",
        "      train_model(model, client_datasets[model_name], batch_size, model_name = model_name, num_epochs=2, device=\"cuda\",test_only=False )\n",
        "\n",
        "    compute_weighted_average_model(model_names, weights, cycle_number = i)\n",
        "    print(\"Weighted average model weights computed\")\n",
        "\n",
        "    print(f\"Testing FL model\")\n",
        "    model = models.resnet18(pretrained=True)\n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = nn.Linear(num_ftrs, 2)  # Assuming you have 2 classes\n",
        "    model.load_state_dict(torch.load(f'weighted_average_model_weights_cycle_{i}.pth'))\n",
        "    accuracy = train_model(model, client_datasets['client_1'], batch_size, model_name = model_name[0], num_epochs=0, device=\"cuda\",test_only=True )\n",
        "    print(f\"Test Accuracy of {model_name[0]} with Federated weights after cycle {i}: {accuracy:.2f}%\")\n",
        "\n",
        "federated_learning(2, model_names, weights, num_epochs=2, batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7Cm79sjJHU_",
        "outputId": "6d21ef2e-c61e-41f9-d179-92bf80aaa596"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Federated Learning Cycle 1\n",
            "Training client_1 model\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Epoch 1/2: 100%|██████████| 22/22 [14:06<00:00, 38.49s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss client_1: 0.38982379804981504\n",
            "Validation Accuracy client_1: 76.69%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/2: 100%|██████████| 22/22 [00:26<00:00,  1.19s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss client_1: 0.2651934500673243\n",
            "Validation Accuracy client_1: 83.78%\n",
            "Test Accuracy client_1: 84.23%\n",
            "Training client_2 model\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/2: 100%|██████████| 22/22 [13:53<00:00, 37.89s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss client_2: 0.3976676896354554\n",
            "Validation Accuracy client_2: 59.80%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/2: 100%|██████████| 22/22 [00:25<00:00,  1.17s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss client_2: 0.20899605317363168\n",
            "Validation Accuracy client_2: 78.04%\n",
            "Test Accuracy client_2: 79.53%\n",
            "Training client_3 model\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/2: 100%|██████████| 22/22 [14:45<00:00, 40.23s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss client_3: 0.3588581552819247\n",
            "Validation Accuracy client_3: 79.39%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/2: 100%|██████████| 22/22 [00:25<00:00,  1.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss client_3: 0.24105370932528702\n",
            "Validation Accuracy client_3: 88.85%\n",
            "Test Accuracy client_3: 85.91%\n",
            "Training client_4 model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/2:   9%|▉         | 2/22 [01:14<12:30, 37.52s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  print(f\"Test Accuracy of Federated Learning Model cycle {i*'*'}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVypAWuXciGn",
        "outputId": "a8503659-afcc-470e-fe2d-b717e86c6d83"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy of Federated Learning Model cycle \n",
            "Test Accuracy of Federated Learning Model cycle *\n",
            "Test Accuracy of Federated Learning Model cycle **\n",
            "Test Accuracy of Federated Learning Model cycle ***\n",
            "Test Accuracy of Federated Learning Model cycle ****\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "model = models.resnet18(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 2)\n",
        "path = f'weighted_average_model_weights_cycle_{i}.pth'\n",
        "model.load_state_dict(torch.load(path))"
      ],
      "metadata": {
        "id": "zRf9WG_hnyJn",
        "outputId": "3862f5ae-6a45-4125-f24d-b5f4353f5dd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i= 0\n",
        "model = models.resnet18(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 2)  # Assuming you have 2 classes\n",
        "model.load_state_dict(torch.load(f'weighted_average_model_weights_cycle_{i}.pth'))\n",
        "accuracy = train_model(model, client_datasets['client_3'], 2, model_name = 'client_1', num_epochs=0, device=\"cuda\",test_only=True )\n",
        "print(f\"Test Accuracy of Federated Learning Model cycle {i}: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "47aQNTyCsbaT",
        "outputId": "bbf58a2a-5588-47a9-c5e7-c61eded51e58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy of Federated Learning Model cycle 0: 66.78%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dco4_Vvathn5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "collapsed_sections": [
        "1wc4kBHWCRR1",
        "_t9G_NbrW_Vd",
        "6AWlwm7lbKZC",
        "3425A3tgbPFU",
        "HxZlUTwObR-C",
        "w1Y4ae1WeGeA",
        "lfweO7RXoqpc",
        "4FIwcjNGpTw0",
        "CWZId9UgsVFA",
        "3oLDlP_Ttd05"
      ],
      "mount_file_id": "1HG4UjxIAw1bJh7ekGvvkEqJC4DxBfJYU",
      "authorship_tag": "ABX9TyNzlIfZncKQ6yuhGCK9qqR1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}